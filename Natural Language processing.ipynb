{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9lRIt3rney5X5izQrLDrR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Isaac-Gathere/Haxmass2021-Part1/blob/main/Natural%20Language%20processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnqDCizkU29H"
      },
      "outputs": [],
      "source": [
        "!pip install keras numpy wget"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary packages\n",
        "import os\n",
        "import io\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, TimeDistributed\n",
        "from keras.utils import to_categorical as keras_to_categorical\n",
        "from keras.utils import pad_sequences\n",
        "import nltk\n",
        "import sys\n",
        "import string"
      ],
      "metadata": {
        "id": "TtfOWQwlYXfn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_corpus(path):\n",
        "\n",
        "    # Check if the path is a directory.\n",
        "    if not os.path.isdir(path):\n",
        "        sys.exit(\"Input path is not a directory\")\n",
        "    \n",
        "    # Read the files in the directory.\n",
        "    files = os.listdir(path)\n",
        "    \n",
        "    # Initialize the lists for the sentences and their tags.\n",
        "    sentences, tags = [], []\n",
        "    \n",
        "    # Loop through the files.\n",
        "    for file in files:\n",
        "        # Open the file.\n",
        "        with open(os.path.join(path, file), 'r') as f:\n",
        "            # Read the lines in the file.\n",
        "            lines = f.readlines()\n",
        "            # Loop through the lines.\n",
        "            for line in lines:\n",
        "                # Split the line into words and their tags.\n",
        "                words_tags = line.split()\n",
        "                words = [wt.split('/')[0] for wt in words_tags]\n",
        "                tags.append([wt.split('/')[1] for wt in words_tags])\n",
        "                sentences.append(words)\n",
        "    \n",
        "    return sentences, tags\n"
      ],
      "metadata": {
        "id": "t31EXUMxY5eA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G8EW1t-pZAaH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}